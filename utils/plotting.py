import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from utils.analysis import arena_regress_rdms
from scipy.stats import ttest_ind

# from utils.analysis import fit_sigmoid, sigmoid
from sklearn.manifold import MDS


def plot_arena_mds(rdms: dict, basetask: str = "animals"):
    """performs MDS on arena task RDMs

    Args:
        rdms (dict): dictionary as generated by arena_compute_rdms()
        basetask (str, optional): domain of base task, either "animals" or "vehicles". Defaults to "animals".
    """
    # valid base task given
    basetask = basetask.lower()
    assert basetask in ["animals", "vehicles"]

    # set color and size vectors for markers
    cols = [
        (x)
        for x in zip(
            np.linspace(0.1, 0.95, 5),
            np.zeros((5,)),
            np.flip(np.linspace(0.1, 0.95, 5)),
        )
    ]
    sizes = np.linspace(5, 60, 5).astype("int")
    x, y = map(lambda x: x.ravel(), np.meshgrid(np.arange(5), np.arange(5)))

    # make figure
    plt.figure(figsize=(5, 6))
    curricula = ["blocked"] * 2 + ["interleaved"] * 2
    tasks = ["speed", "size"] * 2
    idces = [0, 2, 0, 2]
    for i in range(4):
        plt.subplot(2, 2, i + 1)
        # group average rdm
        rdm = rdms[basetask][curricula[i]][:, idces[i], :, :].mean(0)
        mds = MDS(
            metric=True, n_components=2, dissimilarity="precomputed", max_iter=10000
        )
        xy = mds.fit_transform(rdm)
        if basetask == "animals":
            j = 1
            for xi, yi, coords in zip(x, y, xy):
                if j % 2 == 0:
                    plt.scatter(coords[0], coords[1], s=sizes[yi], color=cols[xi])
                else:
                    plt.scatter(
                        coords[0],
                        coords[1],
                        s=sizes[yi],
                        edgecolor=cols[xi],
                        marker="s",
                        facecolor="w",
                    )
                j += 1
        elif basetask == "vehicles":
            j = 1
            for xi, yi, coords in zip(x, y, xy):
                if j % 2 != 0:
                    plt.scatter(coords[0], coords[1], s=sizes[yi], color=cols[xi])
                else:
                    plt.scatter(
                        coords[0],
                        coords[1],
                        s=sizes[yi],
                        edgecolor=cols[xi],
                        marker="s",
                        facecolor="w",
                    )
                j += 1
        plt.title(curricula[i] + " - " + tasks[i])
        plt.axis("square")
        plt.xlabel("mds dim 1")
        plt.ylabel("mds dim 2")
    plt.suptitle(basetask)
    plt.tight_layout()


def sem(x: np.array, ddof: int = 1, ax: int = 0) -> float:
    """computes standard error of mean

    Args:
        x (np.array): array with some data
        ddof (int, optional): degrees of freedom for std estimation. Defaults to 1.
        ax (int, optional): axis of x along which to compte sem. Defaults to 0.

    Returns:
        float: sem of x
    """
    return np.std(x, ddof=1, axis=ax) / np.sqrt(np.shape(x)[ax])


def disp_accuracy(alldata, domain, whichtask="base"):

    # set boundary trials to nan
    alldata[domain]["blocked"]["resp_correct"][
        alldata[domain]["blocked"]["expt_category"] == 0
    ] = np.nan
    alldata[domain]["interleaved"]["resp_correct"][
        alldata[domain]["interleaved"]["expt_category"] == 0
    ] = np.nan

    # compute accuracies
    n_test = alldata[domain]["blocked"]["resp_correct"][:, 400:].shape[1]

    resp_correct = alldata[domain]["blocked"]["resp_correct"][:, 400:]
    resp_category = alldata[domain]["blocked"]["resp_category"][:, 400:]
    expt_domain_test = alldata[domain]["blocked"]["expt_domain"][:, 400:]
    expt_domain_base = alldata[domain]["blocked"]["expt_domain"][:, 0]
    task_mask = np.asarray(
        [
            expt_domain_test[i, :] == expt_domain_base[i]
            for i in range(len(expt_domain_base))
        ]
    )
    resp_correct_blocked = np.array(
        [
            resp_correct[i, task_mask[i, :] == (whichtask == "base")]
            for i in range(len(task_mask))
        ]
    )
    resp_category_blocked = np.array(
        [
            resp_category[i, task_mask[i, :] == (whichtask == "base")]
            for i in range(len(task_mask))
        ]
    )

    resp_correct = alldata[domain]["interleaved"]["resp_correct"][:, 400:]
    resp_category = alldata[domain]["interleaved"]["resp_category"][:, 400:]
    expt_domain_test = alldata[domain]["interleaved"]["expt_domain"][:, 400:]
    expt_domain_base = alldata[domain]["interleaved"]["expt_domain"][:, 0]
    task_mask = np.asarray(
        [
            expt_domain_test[i, :] == expt_domain_base[i]
            for i in range(len(expt_domain_base))
        ]
    )
    resp_correct_interleaved = np.array(
        [
            resp_correct[i, task_mask[i, :] == (whichtask == "base")]
            for i in range(len(task_mask))
        ]
    )
    resp_category_interleaved = np.array(
        [
            resp_category[i, task_mask[i, :] == (whichtask == "base")]
            for i in range(len(task_mask))
        ]
    )

    acc_blocked = np.nanmean(resp_correct_blocked, 1)
    acc_interleaved = np.nanmean(resp_correct_interleaved, 1)
    f, ax = plt.subplots(1, 1, figsize=(2.59, 3.47))
    # ax = ax.ravel()

    # only if meets inclusion criterion (less than 1/4 of trials missed)
    acc_blocked_good = acc_blocked[
        np.isnan(resp_category_blocked).sum(1) < (n_test / 4)
    ]
    acc_interleaved_good = acc_interleaved[
        np.isnan(resp_category_interleaved).sum(1) < (n_test / 4)
    ]
    ax.bar(
        [0, 1],
        [acc_blocked_good.mean(), acc_interleaved_good.mean()],
        yerr=[sem(acc_blocked_good), sem(acc_interleaved_good)],
        zorder=1,
        color=[[0.2, 0.2, 0.2], [0.6, 0.6, 0.6]],
    )
    ax.scatter(
        np.zeros(len(acc_blocked_good))
        - 0.1
        + 0.05 * np.random.randn(len(acc_blocked_good)),
        acc_blocked_good,
        s=3,
        zorder=3,
        color="k",
    )
    ax.scatter(
        np.ones(len(acc_interleaved_good))
        - 0.1
        + 0.05 * np.random.randn(len(acc_interleaved_good)),
        acc_interleaved_good,
        s=3,
        zorder=3,
        color="k",
    )
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.set_xticks([0, 1])
    ax.set_xticklabels(["blocked", "interleaved"])
    ax.set_ylim([0.5, 1])
    ax.set_yticks(np.arange(0, 1.1, 0.25))
    ax.set_yticklabels(np.arange(0, 101, 25))
    ax.set_ylim([0.5, 1])
    ax.set_ylabel("Accuracy (%)")
    ax.set_title("test accuracy - " + domain)

    plt.tight_layout()


def disp_lcurves_training(
    alldata,
    domains=["animals", "vehicles"],
    curricula=["blocked", "interleaved"],
    onlygood=True,
):

    w = 50

    cols = [[0.2, 0.2, 0.2], [0.6, 0.6, 0.6]]
    if onlygood is False:
        # all participants
        plt.figure(figsize=(8.66, 3.07))
        for i, dom in enumerate(domains):
            plt.subplot(1, 2, i + 1)
            for j, cur in enumerate(curricula):
                data_binned = np.array([])
                responses = alldata[dom][cur]["resp_correct"][:, :400]
                idces = np.arange(0, 400, w)
                data_binned = np.empty((responses.shape[0], len(idces)))
                for ii, idx in enumerate(idces):
                    data_binned[:, ii] = np.nanmean(responses[:, idx : idx + w - 1], 1)
                plt.errorbar(
                    np.arange(len(idces)),
                    data_binned.mean(0),
                    yerr=sem(data_binned, 0),
                    color=cols[j],
                    linewidth=2,
                    fmt="o-",
                )
            plt.ylim((0, 1))
            ax = plt.gca()
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)
            plt.title("learning curve - " + dom)
            plt.plot([4, 4], [0, 1], "k--")
            # plt.plot([8, 8], [0, 1], "k-")
            ticks = plt.xticks()
            plt.xticks(
                ticks=ticks[0], labels=[""] + [str(i) for i in np.arange(0, 401, 50)]
            )
            plt.xlim((-1, 8))
            plt.xlabel("trial")
            plt.ylabel("Accuracy (%)")
            ax = plt.gca()
            ax.set_ylim([-0.05, 1])
            ax.set_yticks(np.arange(0, 1.1, 0.25))
            ax.set_yticklabels(np.arange(0, 101, 25))
        plt.suptitle("All participants, training")
    else:
        # learning curve, good ones
        plt.figure(figsize=(8.66, 3.07))
        for i, dom in enumerate(domains):

            mask_blocked = (
                np.isnan(alldata[dom]["blocked"]["resp_category"][:, 400:]).sum(1) < 75
            )
            mask_interleaved = (
                np.isnan(alldata[dom]["interleaved"]["resp_category"][:, 400:]).sum(1)
                < 75
            )

            masks = [mask_blocked, mask_interleaved]
            plt.subplot(1, 2, i + 1)
            for j, cur in enumerate(curricula):
                data_binned = np.array([])
                responses = alldata[dom][cur]["resp_correct"][:, :400]
                idces = np.arange(0, 400, w)
                data_binned = np.empty((responses.shape[0], len(idces)))
                for ii, idx in enumerate(idces):
                    data_binned[:, ii] = np.nanmean(responses[:, idx : idx + w - 1], 1)
                data_binned = data_binned[masks[j], :]
                plt.errorbar(
                    np.arange(len(idces)),
                    data_binned.mean(0),
                    yerr=sem(data_binned, 0),
                    color=cols[j],
                    linewidth=2,
                    fmt="o-",
                )
            plt.ylim((0, 1))
            ax = plt.gca()
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)
            plt.title("learning curve - " + dom)
            plt.plot([4, 4], [0, 1], "k--")
            # plt.plot([8, 8], [0, 1], "k-")
            ticks = plt.xticks()
            plt.xticks(
                ticks=np.arange(-2, 8),
                labels=[""] + [str(i) for i in np.arange(0, 401, 50)],
            )
            plt.xlim((-1, 8))
            plt.xlabel("trial")
            plt.ylabel("Accuracy (%)")
            ax = plt.gca()
            ax.set_ylim([-0.05, 1])
            ax.set_yticks(np.arange(0, 1.1, 0.25))
            ax.set_yticklabels(np.arange(0, 101, 25))
            plt.ylim((0.5, 1))
        plt.suptitle("only good participants, training")
    plt.tight_layout()


def disp_lcurves_test(
    alldata,
    domains=["animals", "vehicles"],
    curricula=["blocked", "interleaved"],
    onlygood=True,
    whichtask="base",
):

    w = 25

    cols = [[0.2, 0.2, 0.2], [0.6, 0.6, 0.6]]
    if onlygood is False:
        # all participants
        plt.figure(figsize=(15, 5))
        for i, dom in enumerate(domains):
            plt.subplot(1, 2, i + 1)
            for j, cur in enumerate(curricula):
                data_binned = np.array([])
                resp_correct = alldata[dom][cur]["resp_correct"][:, 400:]
                resp_category = alldata[dom][cur]["resp_category"][:, 400:]
                expt_domain_test = alldata[dom][cur]["expt_domain"][:, 400:]
                expt_domain_base = alldata[dom][cur]["expt_domain"][:, 0]
                task_mask = np.asarray(
                    [
                        expt_domain_test[i, :] == expt_domain_base[i]
                        for i in range(len(expt_domain_base))
                    ]
                )
                resp_correct = np.array(
                    [
                        resp_correct[i, task_mask[i, :] == (whichtask == "base")]
                        for i in range(len(task_mask))
                    ]
                )
                resp_category = np.array(
                    [
                        resp_category[i, task_mask[i, :] == (whichtask == "base")]
                        for i in range(len(task_mask))
                    ]
                )
                idces = np.arange(0, 150, w)
                data_binned = np.empty((resp_correct.shape[0], len(idces)))
                for ii, idx in enumerate(idces):
                    data_binned[:, ii] = np.nanmean(
                        resp_correct[:, idx : idx + w - 1], 1
                    )
                plt.errorbar(
                    np.arange(len(idces)),
                    data_binned.mean(0),
                    yerr=sem(data_binned, 0),
                    color=cols[j],
                    linewidth=2,
                    fmt="o-",
                )
            plt.ylim((0, 1))
            ax = plt.gca()
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)
            plt.title("learning curve - " + dom)
            # ticks = plt.xticks()
            plt.xticks(
                ticks=np.arange(7), labels=[str(i) for i in np.arange(0, 151, 25)]
            )
            # plt.xlim((-1, 8))
            plt.xlabel("trial")
            plt.ylabel("Accuracy (%)")
            ax = plt.gca()
            ax.set_ylim([-0.05, 1])
            ax.set_yticks(np.arange(0, 1.1, 0.25))
            ax.set_yticklabels(np.arange(0, 101, 25))
        plt.suptitle(f"All participants, test, {whichtask} task")
    else:
        # learning curve, good ones
        plt.figure(figsize=(15, 5))
        for i, dom in enumerate(domains):

            plt.subplot(1, 2, i + 1)
            for j, cur in enumerate(curricula):
                data_binned = np.array([])
                resp_correct = alldata[dom][cur]["resp_correct"][:, 400:]
                resp_category = alldata[dom][cur]["resp_category"][:, 400:]
                expt_domain_test = alldata[dom][cur]["expt_domain"][:, 400:]
                expt_domain_base = alldata[dom][cur]["expt_domain"][:, 0]
                task_mask = np.asarray(
                    [
                        expt_domain_test[i, :] == expt_domain_base[i]
                        for i in range(len(expt_domain_base))
                    ]
                )
                resp_correct = np.array(
                    [
                        resp_correct[i, task_mask[i, :] == (whichtask == "base")]
                        for i in range(len(task_mask))
                    ]
                )
                resp_category = np.array(
                    [
                        resp_category[i, task_mask[i, :] == (whichtask == "base")]
                        for i in range(len(task_mask))
                    ]
                )
                n_test = resp_correct.shape[1]
                mask = np.isnan(resp_category).sum(1) < (n_test / 4)
                idces = np.arange(0, 150, w)
                data_binned = np.empty((resp_correct.shape[0], len(idces)))
                for ii, idx in enumerate(idces):
                    data_binned[:, ii] = np.nanmean(
                        resp_correct[:, idx : idx + w - 1], 1
                    )
                data_binned = data_binned[mask, :]
                plt.errorbar(
                    np.arange(len(idces)),
                    data_binned.mean(0),
                    yerr=sem(data_binned, 0),
                    color=cols[j],
                    linewidth=2,
                    fmt="o-",
                )
            plt.ylim((0, 1))
            ax = plt.gca()
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)
            plt.title("learning curve - " + dom)

            # ticks = plt.xticks()
            plt.xticks(
                ticks=np.arange(7), labels=[str(i) for i in np.arange(0, 151, 25)]
            )
            # plt.xlim((-1, 8))
            plt.xlabel("trial")
            plt.ylabel("Accuracy (%)")
            ax = plt.gca()
            ax.set_ylim([-0.05, 1])
            ax.set_yticks(np.arange(0, 1.1, 0.25))
            ax.set_yticklabels(np.arange(0, 101, 25))
            plt.ylim((0.5, 1))
        plt.suptitle(f"only good participants, test, {whichtask} task")


def disp_lcurves(
    alldata,
    domains=["animals", "vehicles"],
    curricula=["blocked", "interleaved"],
    onlygood=True,
):

    disp_lcurves_training(
        alldata,
        domains=domains,
        curricula=curricula,
        onlygood=onlygood,
    )


def disp_sigmoid_fits(
    choicemats,
    thetas,
    onlygood: bool = False,
    domains: list = ["animals", "vehicles"],
    curricula: list = ["blocked", "interleaved"],
    bothtasks: bool = False,
):
    """
    displays gt data of participant choices together with best fitting sigmoids
    onlygood: fit only to participants who performed above chance (yes/no)
    """

    tasks = ["task_a", "task_b"]
    if onlygood is True:
        tasks = [t + "_good" for t in tasks]
    # task_labels = ["blue store", "orange store"]
    cols = [[0.2, 0.2, 0.2], [0.6, 0.6, 0.6]]
    reldims = [0, 1]
    irreldims = [1, 0]
    # one figure per domain
    for dom in domains:
        f, ax = plt.subplots(1, 1, figsize=(3.81, 3.81))

        for icol, cur in enumerate(curricula):
            choice_rel = []
            choice_irrel = []
            for itask, task in enumerate(tasks):
                choice_rel.append(choicemats[dom][cur][task].mean(reldims[itask] + 1))
                choice_irrel.append(
                    choicemats[dom][cur][task].mean(irreldims[itask] + 1)
                )
            print(np.array(choice_rel).shape)
            choice_rel = np.nanmean(np.array(choice_rel), 0)
            choice_irrel = np.nanmean(np.array(choice_irrel), 0)
            ax.errorbar(
                np.arange(-2, 3),
                np.nanmean(choice_rel, 0),
                yerr=sem(choice_rel, 0),
                fmt="o-",
                color=cols[icol],
            )
            ax.scatter(
                np.arange(-2, 3),
                np.nanmean(choice_rel, 0),
                s=60,
                marker="o",
                color=cols[icol],
            )

            ax.errorbar(
                np.arange(-2, 3),
                np.nanmean(choice_irrel, 0),
                yerr=sem(choice_irrel, 0),
                fmt="x--",
                color=cols[icol],
            )
            ax.scatter(
                np.arange(-2, 3),
                np.nanmean(choice_irrel, 0),
                s=60,
                marker="x",
                color=cols[icol],
            )
            ax.set(ylim=[0, 1], xlim=[-2.2, 2.2])
            ax.set_title(
                dom,
                fontsize=12,
                fontweight="bold",
            )
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)
            ax.set(xlabel="feature value", ylabel="p(accept)")


def disp_param_estimates(
    betas,
    onlygood: bool = False,
    domains: list = ["animals", "vehicles"],
    curricula: list = ["blocked", "interleaved"],
    fitlapse: bool = False,
):
    """
    displays average parameter estimates of sigmoid fit procedure
    onlygood: fit only to participants who performed above chance (yes/no)
    """

    tasks = ["task_a", "task_b"]
    if onlygood is True:
        tasks = [t + "_good" for t in tasks]
    # task_labels = ["blue store (speed)", "orange store"]
    parameters = ["lapse rate", "slope", "offset"] if fitlapse else ["slope", "offset"]
    dimensions = ["rel", "irrel"]
    cols = [[0.2, 0.2, 0.2], [0.6, 0.6, 0.6]]
    for dom in domains:
        for dim in dimensions:
            if fitlapse:
                plt.figure(figsize=(10, 3))
            else:
                plt.figure(figsize=(6, 3))
            for ii, param in enumerate(parameters):
                # average parameter estimates across tasks (orange/blue)
                if not (fitlapse):
                    ii += 1
                p_blocked = np.asarray(
                    [
                        betas[dom]["blocked"][tasks[0]][dim][:, ii],
                        betas[dom]["blocked"][tasks[1]][dim][:, ii],
                    ]
                ).mean(0)
                p_interleaved = np.asarray(
                    [
                        betas[dom]["interleaved"][tasks[0]][dim][:, ii],
                        betas[dom]["interleaved"][tasks[1]][dim][:, ii],
                    ]
                ).mean(0)
                # bar plots with errorbars
                if fitlapse:
                    plt.subplot(1, 3, ii + 1)
                else:
                    plt.subplot(1, 2, ii)
                ax = plt.gca()

                ax.bar(
                    0, p_blocked.mean(), yerr=sem(p_blocked, 0), color=cols[0], zorder=1
                )
                ax.bar(
                    1,
                    p_interleaved.mean(),
                    yerr=sem(p_interleaved, 0),
                    color=cols[1],
                    zorder=1,
                )
                ax.scatter(
                    np.zeros(len(p_blocked))
                    - 0.1
                    + 0.05 * np.random.randn(len(p_blocked)),
                    p_blocked,
                    s=3,
                    zorder=3,
                    color="k",
                )
                ax.scatter(
                    np.ones(len(p_interleaved))
                    - 0.1
                    + 0.05 * np.random.randn(len(p_interleaved)),
                    p_interleaved,
                    s=3,
                    zorder=3,
                    color="k",
                )

                # ax.scatter(
                #     np.zeros((len(p_blocked), 1)) - 0.1, p_blocked, color="k", zorder=3
                # )
                # ax.scatter(
                #     np.ones((len(p_interleaved), 1)) - 0.1,
                #     p_interleaved,
                #     color="k",
                #     zorder=3,
                # )
                tval, pval = stats.ttest_ind(
                    p_blocked.squeeze(), p_interleaved.squeeze()
                )
                ax.set(
                    xticks=[0, 1],
                    xticklabels=("blocked", "interleaved"),
                    ylabel=r"$\beta$ estimate (a.u)",
                    title=param
                    + ", t("
                    + str(
                        np.sum([len(p_blocked.squeeze()), len(p_interleaved.squeeze())])
                    )
                    + ")= "
                    + str(np.round(tval, 3))
                    + "p="
                    + str(np.round(pval, 3)),
                )
                sns.despine()

            plt.suptitle(dom + " - " + dim + " dim", fontweight="bold")
            plt.tight_layout()


def disp_choicemat(cmat):
    plt.imshow(cmat)
    plt.clim(0, 1)
    plt.xlabel("speed")
    plt.ylabel("size")


def disp_choicemats(
    choicemats: dict,
    onlygood: bool = True,
    domains: list = ["animals", "vehicles"],
    curricula: list = ["blocked", "interleaved"],
    whichtask: str = "base",
):
    """
    displays choice probability matrices for each task
    and domain
    """
    tasks = ["task_a", "task_b"]
    if onlygood is True:
        tasks = [t + "_good" for t in tasks]
    task_labels = ["orange store", "blue store"]
    # parameters = ["lapse rate", "slope", "offset"]

    for dom in domains:

        plt.figure(figsize=(5, 5))
        plt.subplot(2, 2, 1)
        cmat = np.nanmean(choicemats[dom]["blocked"][tasks[0]], 0)
        disp_choicemat(cmat)

        plt.title(task_labels[0] + " - blocked")
        plt.subplot(2, 2, 2)
        cmat = np.nanmean(choicemats[dom]["blocked"][tasks[1]], 0)
        disp_choicemat(cmat)
        plt.title(task_labels[1] + " - blocked")

        plt.subplot(2, 2, 3)
        cmat = np.nanmean(choicemats[dom]["interleaved"][tasks[0]], 0)
        disp_choicemat(cmat)
        plt.title(task_labels[0] + " - interleaved")
        plt.subplot(2, 2, 4)
        cmat = np.nanmean(choicemats[dom]["interleaved"]["task_b_good"], 0)
        disp_choicemat(cmat)
        plt.title(task_labels[1] + " - interleaved")
        if not onlygood:
            plt.suptitle(
                dom.capitalize() + " - all subjects, " + whichtask + " task",
                fontweight="bold",
            )
        else:
            plt.suptitle(
                dom.capitalize() + " - only good, " + whichtask + " task",
                fontweight="bold",
            )
        plt.tight_layout()


def disp_rsa_param_estimates(
    betas: dict,
    onlygood: bool = False,
    domains: list = ["animals", "vehicles"],
    curricula: list = ["blocked", "interleaved"],
):
    """
    displays average parameter estimates of model-based rsa on choices

    """

    tasks = ["task_a", "task_b"]
    if onlygood is True:
        tasks = [t + "_good" for t in tasks]
    parameters = ["factorised model", "linear model"]
    cols = [[0.2, 0.2, 0.2], [0.6, 0.6, 0.6]]

    for dom in domains:
        plt.figure(figsize=(6, 3))
        for ii, param in enumerate(parameters):
            # average parameter estimates across tasks (orange/blue)
            p_blocked = betas[dom]["blocked"][:, ii]
            p_interleaved = betas[dom]["interleaved"][:, ii]

            # bar plots with errorbars
            plt.subplot(1, 2, ii + 1)
            ax = plt.gca()
            ax.bar(0, p_blocked.mean(), yerr=sem(p_blocked, 0), color=cols[0], zorder=1)
            ax.bar(
                1,
                p_interleaved.mean(),
                yerr=sem(p_interleaved, 0),
                color=cols[1],
                zorder=1,
            )
            print(
                (
                    np.zeros((len(p_blocked), 1))
                    - 0.1
                    + 0.05 * np.random.randn(len(p_blocked), 1)
                ).shape
            )
            ax.scatter(
                np.zeros((len(p_blocked), 1))
                - 0.1
                + 0.05 * np.random.randn(len(p_blocked), 1),
                p_blocked,
                color="k",
                s=3,
                zorder=3,
            )
            ax.scatter(
                np.ones((len(p_interleaved), 1))
                - 0.1
                + 0.05 * np.random.randn(len(p_interleaved), 1),
                p_interleaved,
                color="k",
                s=3,
                zorder=3,
            )
            tval, pval = stats.ttest_ind(p_blocked, p_interleaved)
            ax.set(
                xticks=[0, 1],
                xticklabels=("blocked", "interleaved"),
                ylabel=r"$\beta$ estimate (a.u)",
                title=param
                + " t("
                + str(np.sum([len(p_blocked.squeeze()), len(p_interleaved.squeeze())]))
                + ")= "
                + str(np.round(tval, 3))
                + "p="
                + str(np.round(pval, 3)),
            )
            sns.despine()

        plt.suptitle(dom, fontweight="bold")
        plt.tight_layout()


def disp_model_estimates(
    thetas: dict,
    domains: list = ["animals", "vehicles"],
    curricula: list = ["blocked", "interleaved"],
):
    """
    displays average parameter estimates of choice model
    """

    parameters = ["bias", "lapse", "slope", "offset"]

    cols = [[0.2, 0.2, 0.2], [0.6, 0.6, 0.6]]
    for dom in domains:
        plt.figure(figsize=(10, 3))
        # average bias across tasks
        for cur in curricula:
            thetas[dom][cur]["bias"] = np.stack(
                (thetas[dom][cur]["bias_a"], thetas[dom][cur]["bias_b"]), axis=1
            ).mean(1)
        for ii, param in enumerate(parameters):
            # average parameter estimates across tasks (orange/blue)
            p_blocked = thetas[dom]["blocked"][param]
            p_interleaved = thetas[dom]["interleaved"][param]
            # bar plots with errorbars
            plt.subplot(1, 4, ii + 1)
            ax = plt.gca()
            ax.bar(0, p_blocked.mean(), yerr=sem(p_blocked, 0), color=cols[0], zorder=1)
            ax.bar(
                1,
                p_interleaved.mean(),
                yerr=sem(p_interleaved, 0),
                color=cols[1],
                zorder=1,
            )

            ax.scatter(
                np.zeros((len(p_blocked), 1))
                - 0.1
                + 0.05 * np.random.randn(len(p_blocked), 1),
                p_blocked,
                color="k",
                s=3,
                zorder=3,
            )
            ax.scatter(
                np.ones((len(p_interleaved), 1))
                - 0.1
                + 0.05 * np.random.randn(len(p_interleaved), 1),
                p_interleaved,
                color="k",
                s=3,
                zorder=3,
            )
            tval, pval = stats.ttest_ind(p_blocked, p_interleaved)
            ax.set(
                xticks=[0, 1],
                xticklabels=("blocked", "interleaved"),
                ylabel="parameter estimate (a.u)",
                title=param
                + " t("
                + str(np.sum([len(p_blocked.squeeze()), len(p_interleaved.squeeze())]))
                + ")= "
                + str(np.round(tval, 3))
                + ", p="
                + str(np.round(pval, 4)),
            )
            sns.despine()

        plt.suptitle(dom, fontweight="bold")
        plt.tight_layout()


def disp_arena_coefficients(
    alldata: dict, whichtrials: str = "base", basetask: str = "animals"
):
    """display regression coefficients (+ stats)

    Args:
        alldata (dict): dictionary with participant data
        whichtrials (str, optional): base or transfer trials. Defaults to "base".
        basetask (str, optional): domain of base task, either "animals" or "vehicles". Defaults to "animals".
    """

    # labelling bugfix:
    if whichtrials == "base":
        omittrials = "transfer"
    elif whichtrials == "transfer":
        omittrials = "base"
    else:
        omittrials = "all"
    coefficients = arena_regress_rdms(alldata, whichtrials=omittrials)
    plt.figure(figsize=(5, 3))
    coefficients = coefficients[basetask]
    plt.bar(
        -0.3,
        coefficients["blocked"][:, 0].mean(),
        yerr=np.std(coefficients["blocked"][:, 0])
        / np.sqrt(len(coefficients["blocked"][:, 0])),
        width=0.2,
        color=(0.2, 0.2, 0.2),
    )
    plt.scatter(
        np.zeros(len(coefficients["blocked"][:, 0]))
        - 0.3
        - 0.05
        + np.random.randn(len(coefficients["blocked"][:, 0])) * 0.01,
        coefficients["blocked"][:, 0],
        s=5,
        color=(0.2, 0.2, 0.2),
        alpha=0.5,
    )
    plt.bar(
        -0.1,
        coefficients["blocked"][:, 1].mean(),
        yerr=np.std(coefficients["blocked"][:, 1])
        / np.sqrt(len(coefficients["blocked"][:, 1])),
        width=0.2,
        color=(0, 0.2, 0.5),
    )
    plt.scatter(
        np.zeros(len(coefficients["blocked"][:, 0]))
        - 0.1
        - 0.05
        + np.random.randn(len(coefficients["blocked"][:, 0])) * 0.01,
        coefficients["blocked"][:, 1],
        s=5,
        color=(0, 0.2, 0.5),
        alpha=0.5,
    )
    plt.bar(
        0.1,
        coefficients["blocked"][:, 2].mean(),
        yerr=np.std(coefficients["blocked"][:, 2])
        / np.sqrt(len(coefficients["blocked"][:, 2])),
        width=0.2,
        color=(0.2, 0.4, 0.8),
    )
    plt.scatter(
        np.zeros(len(coefficients["blocked"][:, 0]))
        + 0.1
        - 0.05
        + np.random.randn(len(coefficients["blocked"][:, 0])) * 0.01,
        coefficients["blocked"][:, 2],
        s=5,
        color=(0.2, 0.4, 0.8),
        alpha=0.5,
    )
    plt.bar(
        0.3,
        coefficients["blocked"][:, 3].mean(),
        yerr=np.std(coefficients["blocked"][:, 3])
        / np.sqrt(len(coefficients["blocked"][:, 3])),
        width=0.2,
        color=(0.2, 0.6, 1),
    )
    plt.scatter(
        np.zeros(len(coefficients["blocked"][:, 0]))
        + 0.3
        - 0.05
        + np.random.randn(len(coefficients["blocked"][:, 0])) * 0.01,
        coefficients["blocked"][:, 3],
        s=5,
        color=(0.2, 0.6, 1),
        alpha=0.5,
    )
    # ----------------------------------------------------------------------------------------------
    a = plt.bar(
        0.7,
        coefficients["interleaved"][:, 0].mean(),
        yerr=np.std(coefficients["interleaved"][:, 0])
        / np.sqrt(len(coefficients["interleaved"][:, 0])),
        width=0.2,
        color=(0.2, 0.2, 0.2),
    )
    plt.scatter(
        np.zeros(len(coefficients["interleaved"][:, 0]))
        + 0.7
        - 0.05
        + np.random.randn(len(coefficients["interleaved"][:, 0])) * 0.01,
        coefficients["interleaved"][:, 0],
        s=5,
        color=(0.2, 0.2, 0.2),
        alpha=0.5,
    )
    b = plt.bar(
        0.9,
        coefficients["interleaved"][:, 1].mean(),
        yerr=np.std(coefficients["interleaved"][:, 1])
        / np.sqrt(len(coefficients["interleaved"][:, 1])),
        width=0.2,
        color=(0, 0.2, 0.5),
    )
    plt.scatter(
        np.zeros(len(coefficients["interleaved"][:, 0]))
        + 0.9
        - 0.05
        + np.random.randn(len(coefficients["interleaved"][:, 0])) * 0.01,
        coefficients["interleaved"][:, 1],
        s=5,
        color=(0, 0.2, 0.5),
        alpha=0.5,
    )
    c = plt.bar(
        1.1,
        coefficients["interleaved"][:, 2].mean(),
        yerr=np.std(coefficients["interleaved"][:, 2])
        / np.sqrt(len(coefficients["interleaved"][:, 2])),
        width=0.2,
        color=(0.2, 0.4, 0.8),
    )
    plt.scatter(
        np.zeros(len(coefficients["interleaved"][:, 0]))
        + 1.1
        - 0.05
        + np.random.randn(len(coefficients["interleaved"][:, 0])) * 0.01,
        coefficients["interleaved"][:, 2],
        s=5,
        color=(0.2, 0.4, 0.8),
        alpha=0.5,
    )
    d = plt.bar(
        1.3,
        coefficients["interleaved"][:, 3].mean(),
        yerr=np.std(coefficients["interleaved"][:, 3])
        / np.sqrt(len(coefficients["interleaved"][:, 3])),
        width=0.2,
        color=(0.2, 0.6, 1),
    )
    plt.scatter(
        np.zeros(len(coefficients["interleaved"][:, 0]))
        + 1.3
        - 0.05
        + np.random.randn(len(coefficients["interleaved"][:, 0])) * 0.01,
        coefficients["interleaved"][:, 3],
        s=5,
        color=(0.2, 0.6, 1),
        alpha=0.5,
    )

    plt.title(f"{basetask} - {whichtrials} tasks")
    plt.ylabel(r"$\beta$ estimate (a.u.)")
    plt.xticks(ticks=[0, 1], labels=["blocked", "interleaved"])
    plt.legend(
        [a, b, c, d],
        ["grid", "relevant", "irrelevant", "diagonal"],
        loc=1,
        frameon=False,
    )
    sns.despine()
    plt.tight_layout()

    # statistical inference
    t, p = ttest_ind(coefficients["blocked"][:, 1], coefficients["interleaved"][:, 1])
    print(f"rel blocked vs interleaved: t({len(coefficients['blocked'])+len(coefficients['interleaved'])})={t:.3f}, p = {p:.4f}") # noqa E501
